Project: AAOIFI Judgmental Dataset — Full automated setup & run (strict, safe, bilingual).

OVERVIEW
You are an automation agent with file access in this Replit workspace. Your job: fix, harden, and run the judgmental dataset pipeline so it reliably produces **2000 verified Arabic** judgmental examples, then **2000 verified English** ones, with strict reference validation against AAOIFI source text. Use token-safe requests, key rotation, model fallback, robust parsing and logging, checkpoints, and final Alpaca + Axolotl-ready outputs.

SECURITY / SECRETS CHECK (MUST BE FIRST)
1. Read environment/Secrets for:
   - GEMINI_KEY_1, GEMINI_KEY_2, GEMINI_KEY_3, GEMINI_KEY_4
2. If any are missing, stop and print exactly:
   "Missing secrets: <list>. Add them to Replit Secrets with those names and rerun."
3. Do NOT print secret values anywhere.

INPUT FILES CHECK
4. Confirm presence of these files under inputs/:
   - arabic_cleaned.txt
   - english_cleaned.txt
   - arabic_chunks.json
   - english_chunks.json
   - arabic_qa_pairs.json
   - english_qa_pairs.json
5. If any missing: print missing list and stop.

MODELS & KEYS POLICY
6. Use three models in priority order:
   - gemini-2.5-pro (primary)
   - gemini-2.5-flash (fallback)
   - gemini-2.5-flash-lite (last-resort fallback)
7. Use keys rotation across the four secrets:
   - load keys = [GEMINI_KEY_1, GEMINI_KEY_2, GEMINI_KEY_3, GEMINI_KEY_4]
   - For each API call try (current_key, current_model). If you receive HTTP 429 or ResourceExhausted, record the API's retryDelay and mark that key blocked until retryDelay elapsed; rotate to next key. If all keys blocked, sleep until the soonest retryDelay then continue.
8. Log key_index, model_used, attempt_count, latency, and http_status for every request to `raw/metadata.jsonl`.

CODE CHANGES & HARDENING (apply edits to these files)
9. Edit `src/gemini_client.py` or create it with robust key-rotation + model-fallback logic that:
   - Reads keys from env
   - Uses concurrent-safe lock for rotating keys
   - Honors API `retryDelay` and blocks keys for that duration
   - Retries on transient internal errors with exponential backoff (max attempts per request = 3)
   - Saves raw responses to `raw/` as `<timestamp>_<seed>_<keyindex>_<model>.json`
10. Edit `src/dataset_generator.py`:
    - Replace Arabic & English prompts with strict JSON-only instructions (temperature=0.0, max_output_tokens=512).
    - Use chunk text from `inputs/*_chunks.json` as primary evidence.
    - If required to search further, use `*_cleaned.txt` to confirm reference (token-overlap >= 0.75).
    - Implement perturbation generation (wrong standard number, polarity flips, date shifts, context-shift).
11. Implement parsing improvements:
    - `_parse_json_response` attempts strict json.loads; if fails, extract first `{...}`, try to balance braces, remove triple-backticks and leading text, then parse.
    - If parsing still fails, mark sample as `raw_failed` and save to `raw/failed/`.
12. Implement `_validate_example_schema` stricter rules:
    - Required fields: id, language, claim, context_chunk_id, context_excerpt, verdict, explanation, reference, suspected_fabrication (bool), generator_model, raw_response_path, meta.
    - If verdict=="True" then reference != "UNKNOWN" and explanation non-empty.
    - Token-overlap(reference, context_excerpt) >= 0.75 (normalize by lowercasing, strip punctuation, whitespace tokenize).
    - If any check fails, push to `raw/failed` with reason.

DATA SOURCING RULES (mandatory)
13. Primary evidence must be the chunk whose id is referenced.
14. If model returns a reference phrase, confirm the phrase exists verbatim in the chunk or in the cleaned full-text (with token overlap >= 0.75). Otherwise set reference="UNKNOWN" and suspected_fabrication=true; verdict must be "False".
15. Use seeds from `*_qa_pairs.json` to generate claim seeds. Use seeds to make both True (from correct slicing of chunk) and False (via perturbations) examples.

SMOKE TEST (strict)
16. After code changes, run smoke test:
    - Run `python -m scripts.validate_smoke_test --lang ar --count 20`
    - Criteria to pass: >=90% valid examples by schema, fabrication_rate <= 5% (measured as suspected_fabrication true fraction).
17. If smoke test fails: print top 10 failure reasons with sample raw paths, then stop for human review. Do not proceed to full generation.

FULL GENERATION (only if smoke passes)
18. For Arabic:
    - Target: 2000 **valid** examples (valid == passes schema and not suspected_fabrication=true for True examples)
    - Save validated examples to `data/generation_stage_B/ar/judgmental_ar_final.jsonl`
    - Save every raw model response to `raw/`
    - Checkpoint every 50 valid examples into `progress/` (both a JSONL snapshot and a human-readable progress.txt)
19. After Arabic done, run the English generation similarly (target 2000) and save to `data/generation_stage_B/en/judgmental_en_final.jsonl`
20. Each example must include meta: confidence (0-1), seed_id, chunk_id, generator_model.

ALPACA & AXOLOTL PREP
21. After each language done:
    - Create Alpaca JSONL for that language: `output/alpaca/judgmental_alpaca_ar.jsonl` and `..._en.jsonl`.
    - Create train/val/test splits (80/10/10) in `data/...`.
    - Create `config.example.yaml` for Axolotl, with LoRA settings and the expected data paths.

CLEANUP & ARCHIVE
22. Move old unnecessary raw files into `archive/` and keep only the last 50 raw files unarchived. Do not delete inputs.
23. Create a `logs/audit_run_<timestamp>.log` summary with: valid_count, invalid_count, suspected_fabrication_count, top failure reasons, time_elapsed.

REPORTING
24. After smoke test (and after each big step), print a concise summary:
    - For smoke test: valid_count / total_count, fabrication_rate, top-5 failure reasons and example raw paths.
    - For full generation: total_valid_produced, time taken, last checkpoint path.

IMPLEMENTATION NOTES (hard constraints)
25. All network calls must be robust: timeouts, retries, backoff, and key rotation; never include keys in logs.
26. Use chunk-based context only for primary verification; use the full cleaned file only for secondary confirmation.
27. Persist progress frequently so the pipeline resumes cleanly after interruption.

DEVELOPMENT ACTIONS (immediately, in sequence)
A. Verify Secrets exist (stop if not).
B. Verify inputs exist (stop if not).
C. Apply code edits to `src/gemini_client.py`, `src/dataset_generator.py`, and `scripts/validate_smoke_test.py` as described.
D. Run lint/quick tests.
E. Run smoke test for Arabic (20). Print full evaluation JSON.
F. If smoke passes, continue Arabic full generation; otherwise stop and print diagnostics.

OUTPUT: After finishing step E (smoke), print the JSON summary to stdout. If pass, continue and show progress every 50 examples. If cannot complete due to quota or API blocks, save the resume state and print next recommended action.

START NOW. Remember:
- Read keys from Secrets only.
- Do not echo keys.
- Save all raw responses.
- Strict reference verification required (≥75% token overlap).

If you encounter any syntax errors while applying modifications, print the full traceback and stop.

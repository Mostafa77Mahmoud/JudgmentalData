# Replit agent prompt (English)

You are an automated **repo agent** with read/write access to the repository. Your job: apply a set of robust fixes to the dataset generation + verification pipeline, run the Arabic smoke test, and produce a concise failure/success report with raw-response paths. Do not ask for permission — execute the changes and record what you changed and why. If anything cannot be made to work, save raw outputs and explain what you tried.

**Goals (in order):**

1. Fix `Object of type RepeatedComposite is not JSON serializable` (protobuf / repeated fields).
2. Make response text extraction robust (handle missing `response.text`, `parts`, `finish_reason`, etc.).
3. Handle `finish_reason == 2`, partial/no-text responses, and 429 quota errors gracefully with backoff, key rotation, and fallback to a single stable verifier model.
4. Truncate `context_excerpt` to max 512 chars before sending.
5. Reduce batch size and add one-by-one fallback if a batch verify fails.
6. Save every raw API response to `raw/` with timestamped filenames, and record a summary in `data/generation_stage_B/ar/smoke_test_summary.json`.
7. Run the smoke test for Arabic and save the summary and failing raw paths.

---

## Files to change & exact edits (apply these programmatically)

### 1) `src/gemini_client.py`

* Add imports:

```python
import json, time, os, logging
from google.protobuf.json_format import MessageToDict
logger = logging.getLogger(__name__)
```

* Add helper utilities (paste into the file, use them wherever responses are parsed/saved):

```python
def save_raw_body(obj, prefix):
    os.makedirs("raw", exist_ok=True)
    ts = int(time.time())
    path = f"raw/{ts}_{prefix}.resp.json"
    try:
        if hasattr(obj, "text"):
            body_text = obj.text
        else:
            body_text = json.dumps(obj, ensure_ascii=False, default=lambda o: repr(o))
    except Exception:
        body_text = repr(obj)
    with open(path, "w", encoding="utf8") as f:
        f.write(body_text)
    return path

def safe_serialize_response(resp):
    # Try common json() accessor
    try:
        if hasattr(resp, "json"):
            try:
                return resp.json()
            except Exception:
                pass
    except Exception:
        pass

    # Try protobuf conversion
    try:
        return MessageToDict(resp)
    except Exception:
        pass

    # Last resort: JSON-serializable conversion
    try:
        return json.loads(json.dumps(resp, default=lambda o: getattr(o, "__dict__", repr(o)), ensure_ascii=False))
    except Exception:
        saved = save_raw_body(resp, "error_proto")
        raise ValueError(f"Unable to serialize response to JSON (saved raw to {saved})")
```

* Replace direct uses of `response.text` / `resp.json()` with `safe_serialize_response(resp)` and always call `save_raw_body(resp, modelname)` right after receiving the raw API response.

### 2) Robust text extraction (new helper)

Add this to `src/gemini_client.py` or a new `src/response_utils.py` and import accordingly:

```python
def extract_text_from_parsed(body_dict):
    """
    body_dict is the result of safe_serialize_response (dict or list).
    Return a string if any candidate text found, else None.
    """
    if not isinstance(body_dict, dict):
        return None

    # common top-level keys to check
    for key in ("candidates", "outputs", "output", "choices", "responses", "responses_list"):
        val = body_dict.get(key)
        if isinstance(val, list) and val:
            first = val[0]
            # check for parts structure
            if isinstance(first, dict):
                out = first.get("output") or first.get("response") or first
                if isinstance(out, dict) and "parts" in out and isinstance(out["parts"], list):
                    parts = "".join(p.get("text","") if isinstance(p, dict) else str(p) for p in out["parts"])
                    if parts.strip():
                        return parts
                # check common string fields inside first
                for tkey in ("text","content","message","content_text"):
                    if isinstance(first.get(tkey), str) and first.get(tkey).strip():
                        return first.get(tkey)
        elif isinstance(val, dict):
            for tkey in ("text","content","message"):
                if isinstance(val.get(tkey), str) and val.get(tkey).strip():
                    return val.get(tkey)

    # fallback keys at top-level
    for k in ("text","output_text","response_text","content"):
        if isinstance(body_dict.get(k), str) and body_dict.get(k).strip():
            return body_dict.get(k)
    return None
```

* Use `extract_text_from_parsed(safe_serialize_response(resp))`.
* If it returns `None`, **do not** treat as verified: call `save_raw_body(resp, "notext")`, set candidate status to `NoTextPartsError` and store path for manual review.

### 3) finish\_reason / partial handling & backoff / quota logic

* Wherever you check the API response finish\_reason, implement logic:

  * If `finish_reason == 2` or extracted text is `None`:

    * Save raw response.
    * Retry with backoff and rotate to next API key up to 5 attempts.
    * If after retries still failing, mark the candidate for manual\_review and continue the smoke run.
  * If response contains quota error (HTTP 429):

    * Parse returned quota details, log them (but do NOT print keys). Increase backoff for that key (sleep 60 \* attempt seconds) then rotate keys.
    * If 429 persists for >2 attempts, switch to `SINGLE_MODEL_FALLBACK` and reduce batch size to 1.

Suggested backoff schedule (implement):

```python
BACKOFF = [1.0, 2.0, 4.0, 8.0, 16.0]  # add jitter ±20%
MAX_ATTEMPTS = 5
```

### 4) Batch verify fallback

* `BATCH_VERIFY_SIZE` default = `4`. If a batch fails after retries, re-run verification for that batch **one-by-one** and log which candidate(s) cause protobuf/serialization/finish problems. Save all failing raw responses.

### 5) Truncate `context_excerpt`

* In `src/dataset_generator.py` (before sending to model):

```python
MAX = 512
if len(example["context_excerpt"]) > MAX:
    logger.warning("Invalid example: context_excerpt exceeds %d characters", MAX)
    example["context_excerpt"] = example["context_excerpt"][:MAX-3] + "..."
    # append original excerpt to data/invalid_excerpts.jsonl for later manual review
    with open("data/invalid_excerpts.jsonl","a",encoding="utf8") as f:
        f.write(json.dumps({"id": example["id"], "original_excerpt_len": len(example["context_excerpt"])}) + "\n")
```

### 6) Save every raw API response

* Immediately after receiving a response object `resp`, call:

```python
raw_path = save_raw_body(resp, model_name)
logger.info("Saved raw response to %s", raw_path)
```

* Include `raw_path` in the verification record.

### 7) Smoke test command & output files

* After the code changes, run:

```bash
python -m src.dataset_generator --smoke ar --count 20
```

* Produce `data/generation_stage_B/ar/smoke_test_summary.json` with fields:

```json
{
  "generated_count": 26,
  "verified_local": 6,
  "verified_model": 0,
  "fabrication_rate": 100.0,
  "failed_raw_paths": ["raw/17566_xxx...resp.json", "..."],
  "notes": "short summary of actions and fallback used"
}
```

* Also save `logs/smoke_failure_summary.json` with errors and first 5 raw paths.

### 8) Commit message

* Commit all changes with:

```
chore: fix protobuf serialization, robust text extraction, quota/backoff, truncate excerpts, batch fallback
```

---

## Recommended configuration (place in `config/verifier_config.json` or env)

```json
{
  "DEFAULT_MODELS": ["models/gemini-2.5-pro","models/gemini-2.5-flash","models/gemini-2.5-flash-lite"],
  "SINGLE_MODEL_FALLBACK": "models/gemini-2.5-flash-lite",
  "BATCH_VERIFY_SIZE": 4,
  "MAX_EXCERPT_CHARS": 512,
  "MAX_SMOKE_EXAMPLES": 20,
  "MAX_API_ATTEMPTS": 5,
  "BACKOFF_SCHEDULE": [1,2,4,8,16]
}
```

**Important note about single-model fallback**: using multiple verifier models increases heterogeneity in response structure (different `parts`, `candidates`, finish reasons), which can cause serialization/parse failures and inconsistent verdicts. For verification phase, prefer **one stable model** (the `SINGLE_MODEL_FALLBACK`) and keep multiple models only for **generation** if you need diversity. I recommend turning on `SINGLE_MODEL_FALLBACK` for the smoke-test run.

---

## Reporting requirements (what you must print / save after run)

1. Create `data/generation_stage_B/ar/smoke_test_summary.json` (structure above).
2. Create `logs/smoke_failure_summary.json` with:

   * fabrication\_rate (percentage)
   * total candidates
   * number saved to `manual_review/`
   * list (first 10) failing raw file paths
3. Print to STDOUT:

   * brief summary line: `SMOKE TEST: generated X, local_verified Y, model_verified Z, fabrication_rate P%`
   * `Top 5 failing raw files: raw/xxxx`
   * `If quota errors were hit, print the quota metric names & advice to increase quota (do not print keys).`
4. Commit changes with the message above.

---

## If anything fails while applying patches

* Save a patch file `fixes/failed_patch_diff.txt` containing the intended diffs or file contents you tried to write.
* Save raw logs to `raw/` and include raw paths in the summary.
* Do not push API keys or secrets to git.

---

When finished, respond here with:

1. A one-paragraph summary of what you changed (file list + main code snippets).
2. The contents of `data/generation_stage_B/ar/smoke_test_summary.json` as produced.
3. The first 5 raw response file paths and the first 200 characters of each (for quick triage).
4. Any blocking errors you could not fix and suggested next steps.

Now implement the edits, run the smoke test, and produce the requested outputs.
